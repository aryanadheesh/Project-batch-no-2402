{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9f14a808",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "def display_header_tags(url):\n",
    "    response = requests.get(url)\n",
    "    soup = BeautifulSoup(response.text, 'html.parser')\n",
    "    \n",
    "    header_tags = soup.find_all(['h1', 'h2', 'h3', 'h4', 'h5', 'h6'])\n",
    "    \n",
    "    for tag in header_tags:\n",
    "        print(tag.text.strip())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "397d1246",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Header tags from Wikipedia.org:\n",
      "Main Page\n",
      "Welcome to Wikipedia\n",
      "From today's featured article\n",
      "Did you knowÂ ...\n",
      "In the news\n",
      "On this day\n",
      "Today's featured picture\n",
      "Other areas of Wikipedia\n",
      "Wikipedia's sister projects\n",
      "Wikipedia languages\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    url = \"https://en.wikipedia.org/wiki/Main_Page\"\n",
    "    print(\"Header tags from Wikipedia.org:\")\n",
    "    display_header_tags(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5dcd3ba9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty DataFrame\n",
      "Columns: []\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "\n",
    "url = \"https://presidentofindia.nic.in/former-presidents.htm\"\n",
    "response = requests.get(url)\n",
    "soup = BeautifulSoup(response.text, 'html.parser')\n",
    "table = soup.find('table', class_='table')\n",
    "\n",
    "data = []\n",
    "if table:\n",
    "    for row in table.find_all('tr')[1:]:\n",
    "        name, term = [cell.text.strip() for cell in row.find_all('td')]\n",
    "        data.append({'Name': name, 'Term of Office': term})\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "38000bac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty DataFrame\n",
      "Columns: [Restaurant Name, Cuisine, Location, Ratings, Image URL]\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "\n",
    "url = \"https://www.dineout.co.in\"\n",
    "response = requests.get(url)\n",
    "\n",
    "soup = BeautifulSoup(response.content, 'html.parser')\n",
    "\n",
    "restaurant_names = soup.find_all('h2', class_='restnt-name ellipsis')\n",
    "cuisines = soup.find_all('span', class_='double-line-ellipsis cuisine')\n",
    "locations = soup.find_all('div', class_='restnt-loc ellipsis')\n",
    "ratings = soup.find_all('span', class_='rating-value')\n",
    "image_urls = soup.find_all('img', class_='lazyload')\n",
    "\n",
    "restaurant_list = []\n",
    "cuisine_list = []\n",
    "location_list = []\n",
    "rating_list = []\n",
    "image_url_list = []\n",
    "\n",
    "for name in restaurant_names:\n",
    "    restaurant_list.append(name.text.strip())\n",
    "\n",
    "for cuisine in cuisines:\n",
    "    cuisine_list.append(cuisine.text.strip())\n",
    "\n",
    "for location in locations:\n",
    "    location_list.append(location.text.strip())\n",
    "\n",
    "for rating in ratings:\n",
    "    rating_list.append(rating.text.strip())\n",
    "\n",
    "for image in image_urls:\n",
    "    image_url_list.append(image['data-src'])\n",
    "\n",
    "data = {\n",
    "    'Restaurant Name': restaurant_list,\n",
    "    'Cuisine': cuisine_list,\n",
    "    'Location': location_list,\n",
    "    'Ratings': rating_list,\n",
    "    'Image URL': image_url_list\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2e867437",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'find_all'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 12\u001b[0m\n\u001b[0;32m      9\u001b[0m movie_table \u001b[38;5;241m=\u001b[39m soup\u001b[38;5;241m.\u001b[39mfind(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtable\u001b[39m\u001b[38;5;124m\"\u001b[39m, {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mclass\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mchart\u001b[39m\u001b[38;5;124m\"\u001b[39m})\n\u001b[0;32m     11\u001b[0m movie_data \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m---> 12\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m row \u001b[38;5;129;01min\u001b[39;00m movie_table\u001b[38;5;241m.\u001b[39mfind_all(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtr\u001b[39m\u001b[38;5;124m\"\u001b[39m)[\u001b[38;5;241m1\u001b[39m:\u001b[38;5;241m101\u001b[39m]:\n\u001b[0;32m     13\u001b[0m     columns \u001b[38;5;241m=\u001b[39m row\u001b[38;5;241m.\u001b[39mfind_all(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtd\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     14\u001b[0m     name \u001b[38;5;241m=\u001b[39m columns[\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m.\u001b[39ma\u001b[38;5;241m.\u001b[39mtext\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'find_all'"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "\n",
    "url = \"https://www.imdb.com/chart/top/\"\n",
    "response = requests.get(url)\n",
    "soup = BeautifulSoup(response.text, 'html.parser')\n",
    "\n",
    "movie_table = soup.find(\"table\", {\"class\": \"chart\"})\n",
    "\n",
    "movie_data = []\n",
    "for row in movie_table.find_all(\"tr\")[1:101]:\n",
    "    columns = row.find_all(\"td\")\n",
    "    name = columns[1].a.text\n",
    "    rating = columns[1].find(\"strong\").text\n",
    "    year = columns[1].span.text.strip(\"()\")\n",
    "    movie_data.append((name, rating, year))\n",
    "\n",
    "df = pd.DataFrame(movie_data, columns=[\"Name\", \"Rating\", \"Year of Release\"])\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2335cb3f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
